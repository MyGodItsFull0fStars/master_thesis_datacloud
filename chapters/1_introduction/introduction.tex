\chapter{Introduction}
\label{ch:introduction}

    This chapter covers the introduction of the master thesis.
    First, the motivation and scope of the thesis will be described in section \ref{sec:motivation-and-scope-introduction}.
    Followed by the explanation, what the existing research problems are, that we want to improve upon in section \ref{sec:research-problems-introduction}. Next are the research objectives in section \ref{sec:research-objectives-introduction}, that describe briefly what the gained insights and improvements upon the research problems are. In the section \ref{sec:research-methodology-introduction} the methodology of this thesis is described. And in the section \ref{sec:thesis-outline-introduction} the outline of the thesis briefly describes the structure and content of all subsequent chapters.

        \section{Motivation and Scope}
        \label{sec:motivation-and-scope-introduction}

            This masters thesis is a product of the work done for the project \emph{DataCloud} and a produced paper \emph{Big Data Pipeline Scheduling and Adaptation on the Computing Continuum} \cite{kimovskiBigDataPipeline2022}.

            \begin{quote}
                The Computing Continuum, covering Cloud, Fog, and Edge systems, promises to provide on-demand resource-as-a-service for Internet applications with diverse requirements, ranging from extremely low latency to high-performance processing. However, eminent challenges in automating the resources management of Big Data pipelines across the Computing Continuum remain. The resource management and adaptation for Big Data pipelines across the Computing Continuum require significant research effort, as the current data processing pipelines are dynamic. In contrast, traditional resource management strategies are static, leading to inefficient pipeline scheduling and overly complex process deployment. To address these needs, we propose in this work a scheduling and adaptation approach implemented as a software tool to lower the technological barriers to the management of Big Data pipelines over the Computing Continuum. The approach separates the static scheduling from the run-time execution, em-powering domain experts with little infrastructure and software knowledge to take an active part in the Big Data pipeline adaptation. We conduct a feasibility study using a digital healthcare use case to validate our approach. We illustrate concrete scenarios supported by demonstrating how the scheduling and adaptation tool and its implementation automate the management of the lifecycle of a remote patient monitoring, treatment, and care pipeline. \cite{kimovskiBigDataPipeline2022}
            \end{quote}
            Our motivation is to improve the resource utilisation in systems consisting of a vast amount of computing resources, which in term also results in reduced costs for the providers as well as reduced energy consumption based on the amount of tasks finished.
            The wastage occurring in utilizing resources on large scale systems (or computing clusters) is further described in sections \ref{sec:public-cloud-provider-traces-in-available-data-related-work} and \ref{sec:data-analysis-evaluation}.
            The reduction of the resource wastage is presented by our \nameref{sec:scheduling-and-adaptation-background} approach. 
            This approach consists of two main parts. One is the matching game based scheduling algorithm, which is presented in the publication \emph{Matching-based Scheduling of Asynchronous Data Processing Workflows on the Computing Continuum} \cite{mehranMatchingbasedSchedulingAsynchronous2022} that decides which tasks are mapped to a resource via a two-sided ranking procedure, and second is the adaptation, that consists of continuous monitoring of the tasks and resources, as well as analysis of both and adapting them depending with the help of various tools.

        % this is a test \cite{datacloudAbout}
        \section{Research Problems}
        \label{sec:research-problems-introduction}

        \section{Research Objectives}
        \label{sec:research-objectives-introduction}

        \section{Research Methodology}
        \label{sec:research-methodology-introduction}
        
        \section{Thesis Outline}
        \label{sec:thesis-outline-introduction}

            First, in chapter \nameref{ch:background} the necessary background regarding monitoring, computation on large scale distributed systems, a scheduling and adaptation approach and forecast prediction with machine learning is explained, followed by related work in machine learning based forecast prediction and findings in publicly available data traces.
            In the chapter \nameref{ch:model-methodology} the methodology of this thesis is explained. 
            In chapter \nameref{ch:architecture-and-implementation} the architecture of the software is explained, followed by the preprocessing of data traces mentioned in \nameref{sec:public-cloud-provider-traces-in-available-data-related-work} and the adaptation approach used.
            Next, in chapter \nameref{ch:evaluation-and-results} an analysis on the available data is done, then the evaluation setup on how to set up the software is explained, followed by the different scenarios that were evaluated. 
            Finalizing the thesis with the chapter \nameref{ch:conclusions-and-future-work} that contains the conclusions about the findings of the evaluation in \nameref{sec:conclusions} as well as the \nameref{sec:future-work} that mentions possible improvements upon the current state of the software.


