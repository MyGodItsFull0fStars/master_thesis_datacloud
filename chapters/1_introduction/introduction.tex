\chapter{Introduction}
\label{ch:introduction}

    Modern large-scale systems that contain a vast amount of heterogeneous resources require complex workflow sequences in order to functionally operate. Additionally, specific domain knowledge is required to be able to properly map tasks residing on a big data pipeline onto heterogeneous resources. Yet, this often results in a degradation of the performance of the system since research shows that humans tend to over-provision the available resources.

    \begin{quote}
        In a data center, computing resources such as CPU and memory are usually managed by a resource manager. The resource manager accepts resource requests from users and allocates resources to their applications. A commonly known problem in resource management is that users often request more resources than their applications actually use. This leads to the degradation of overall resource utilization in a data center. \cite{thonglekImprovingResourceUtilization2019}
    \end{quote}

    This chapter covers the introduction of the master thesis.
    First, the motivation and scope of the thesis will be described in section \ref{sec:motivation-and-scope-introduction}.
    Followed by the explanation, of what the existing research problems are, that we want to improve upon in section \ref{sec:research-problems-introduction}. Next are the research objectives in section \ref{sec:research-objectives-introduction}, which describe briefly what the gained insights and improvements upon the research problems are. In section \ref{sec:research-methodology-introduction} the methodology of this thesis is described. And in section \ref{sec:thesis-outline-introduction} the outline of the thesis briefly describes the structure and content of all subsequent chapters.

        \section{Motivation and Scope}
        \label{sec:motivation-and-scope-introduction}

            This masters thesis is a product of the work done for the project \emph{DataCloud} and a produced paper \emph{Big Data Pipeline Scheduling and Adaptation on the Computing Continuum} \cite{kimovskiBigDataPipeline2022}.

            \begin{quote}
                The Computing Continuum, covering Cloud, Fog, and Edge systems, promises to provide on-demand resource-as-a-service for Internet applications with diverse requirements, ranging from extremely low latency to high-performance processing. However, eminent challenges in automating the resources management of Big Data pipelines across the Computing Continuum remain. The resource management and adaptation for Big Data pipelines across the Computing Continuum require significant research effort, as the current data processing pipelines are dynamic. In contrast, traditional resource management strategies are static, leading to inefficient pipeline scheduling and overly complex process deployment. To address these needs, we propose in this work a scheduling and adaptation approach implemented as a software tool to lower the technological barriers to the management of Big Data pipelines over the Computing Continuum. The approach separates the static scheduling from the run-time execution, empowering domain experts with little infrastructure and software knowledge to take an active part in the Big Data pipeline adaptation. We conduct a feasibility study using a digital healthcare use case to validate our approach. We illustrate concrete scenarios supported by demonstrating how the scheduling and adaptation tool and its implementation automate the management of the lifecycle of a remote patient monitoring, treatment, and care pipeline. \cite{kimovskiBigDataPipeline2022}
            \end{quote}
            Our motivation is to improve the resource utilisation in systems consisting of a vast amount of computing resources, which in term also results in reduced costs for the providers as well as reduced energy consumption based on the number of tasks finished.
            The wastage occurring in utilizing resources on large-scale systems (or computing clusters) is further described in sections \ref{sec:public-cloud-provider-traces-in-available-data-related-work} and \ref{sec:data-analysis-evaluation}.
            The reduction of resource wastage is presented by our \nameref{sec:scheduling-and-adaptation-background} approach. 
            This approach consists of two main parts. One is the matching game-based scheduling algorithm, which is presented in the publication \emph{Matching-based Scheduling of Asynchronous Data Processing Workflows on the Computing Continuum} \cite{mehranMatchingbasedSchedulingAsynchronous2022} that decides which tasks are mapped to a resource via a two-sided ranking procedure, and second is the adaptation, that consists of continuous monitoring of the tasks and resources, as well as analysis of both and adapting them depending with the help of various tools.

        % this is a test \cite{datacloudAbout}
        \section{Research Problems}
        \label{sec:research-problems-introduction}

        The deviation of the predicted provisioning or utilisation of heterogeneous resources done by humans often leads to the degradation of the entire system. That degradation includes deployed tasks not finishing within an expected time frame or even the failure of a resource, degrading the stability of the system further.
        \begin{quote}
            In practice, the planned or expected performance of production units often deviates from the actual performance. Most of these deviations are negative, which means that the actual performance is worse than the expected performance. Apparently, expectations about future performances are often too optimistic. \cite{stoopComplexitySchedulingPractice1996}
        \end{quote}
        Naive predictions of the resource utilisation generated by humans are likely to be over-utilising resources, which leads to resource wastage since those resources are not optimally operating. 
        
        These deviations from the actual values are also referred to as \emph{disturbances}.
        As is stated in \cite{stoopComplexitySchedulingPractice1996}, these disturbances can be divided into three categories:
        \begin{enumerate}
            \item Disturbances regarding the capacity,
            \item Disturbances related to orders,
            \item Disturbances related to the measurement of data.
        \end{enumerate}
        While the paper uses the disturbances on \emph{production scheduling}, i.e. finding a schedule for a real facility, the propositions can be translated into our domain of distributed systems that represent the machines/workers and big data pipelines filled with tasks that represent the tasks that are to be scheduled to the machines. After scheduling and deploying the tasks onto the machines, they need to be executed or finished by a worker.
        Capacity disturbances are caused by the machine's capacity and involve scenarios such as partial or complete failure of a hardware resource or trying to execute tasks on resources that are not capable of handling those tasks because the specific requirements are not met. 
        
        Order-related disturbances are aspects that delay the process of individual orders (tasks).
        This could be the unavailability of required data that is calculated by a preceding task the current task depends on which has not finished its execution. 

        The disturbance related to the measurement of data is that of processing times and hardware utilisation requirements that are estimated before deploying a task onto the distributed system. 
        This type of disturbance is the aforementioned deviation of the predicted utilisation of heterogeneous resources that are investigated in this thesis. These cover the hardware utilisation requirements and the already existing estimations done by domain experts and users. While analysing the monitoring traces of popular cloud providers, it becomes apparent that hardware is not optimally used.

        % explain that a subset of the problem is np-hard/complete

        
        \section{Research Objectives}
        \label{sec:research-objectives-introduction}

            The research objectives of this thesis work are to provide a prediction method for a distributed system handling big data that can predict how much system resources are necessary and provide a rule-based analyser that monitors the system components for over-utilisation.

        \section{Research Goals}
        \label{sec:goals-results-introduction}

            \begin{itemize}
                \item An analysis of different publicly available monitoring traces.
                \item Reviewing different methods and theories for resource utilisation prediction.
                \item A proof of concept machine learning component that is capable of improving resource utilisation compared to other methods, which includes evaluation of the improvement.
                \item Providing the adapted data prediction done by the machine learning component in a reasonable time frame in order to be usable by the matching-based scheduler.
                
            \end{itemize}
            
        \section{Research Methodology}
        \label{sec:research-methodology-introduction}

        

        
        \section{Thesis Outline}
        \label{sec:thesis-outline-introduction}

            First, in chapter \nameref{ch:background} the necessary background regarding monitoring, computation on large-scale distributed systems, a scheduling and adaptation approach and forecast prediction with machine learning is explained, followed by related work in machine learning-based forecast prediction and findings in publicly available data traces.
            In chapter \nameref{ch:model-methodology} the methodology of this thesis is explained. 
            In chapter \nameref{ch:architecture-and-implementation} the architecture of the software is explained, followed by the preprocessing of data traces mentioned in \nameref{sec:public-cloud-provider-traces-in-available-data-related-work} and the adaptation approach used.
            Next, in chapter \nameref{ch:evaluation-and-results} an analysis of the available data is done, and then the evaluation setup on how to set up the software is explained, followed by the different scenarios that were evaluated. 
            Finalizing the thesis with the chapter \nameref{ch:conclusions-and-future-work} that contains the conclusions about the findings of the evaluation in \nameref{sec:conclusions} as well as the \nameref{sec:future-work} that mentions possible improvements upon the current state of the software.


