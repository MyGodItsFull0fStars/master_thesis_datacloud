\chapter{Introduction}
\label{ch:introduction}

    Modern large-scale distributed infrastructures that consist of a vast amount of heterogeneous resources require complex workflow sequences in order to functionally operate. Additionally, specific domain knowledge is required to be able to properly map tasks residing on a big data pipeline onto heterogeneous resources. Yet, this often results in a degradation of the performance of the system since research shows that humans tend to over-provision the available resources.

    \begin{quote}
        In a data center, computing resources such as CPU and memory are usually managed by a resource manager. The resource manager accepts resource requests from users and allocates resources to their applications. A commonly known problem in resource management is that users often request more resources than their applications actually use. This leads to the degradation of overall resource utilization in a data center \cite{thonglekImprovingResourceUtilization2019}.
    \end{quote}

    This chapter covers the introduction of the master thesis.
    First, the motivation and scope of the thesis will be described in section \ref{sec:motivation-and-scope-introduction}.
    Followed by the explanation, of what the existing research problems are, that we want to improve upon in section \ref{sec:research-problems-introduction}. Next are the research objectives in section \ref{sec:research-objectives-introduction}, which describe briefly what the gained insights and improvements upon the research problems are. In section \ref{sec:research-methodology-introduction} the methodology of this thesis is described. And in section \ref{sec:thesis-outline-introduction} the outline of the thesis briefly describes the structure and content of all subsequent chapters.

        \section{Motivation and Scope}
        \label{sec:motivation-and-scope-introduction}

            The motivation is to improve resource utilisation in distributed infrastructures. The targeted distributed infrastructures consist of a vast amount of computing resources on cloud, fog and edge layers.
            Mapping and deploying tasks on these infrastructures is a challenging problem. In order to enable large-scale distributed infrastructures to function properly, it is necessary to provide estimates regarding the resource utilisation of deployable tasks to these infrastructures.
            A major problem when providing resource utilisation estimates is their quality of accuracy, as shown by the authors of \cite{thonglekImprovingResourceUtilization2019}, tasks provided by users overestimate the resource utilisation by more than $30\%$ on average. 
            This results in a higher resource allocation than necessary to execute and finish tasks in time and also results in a less stable infrastructure since tasks might not be deployed on fitting resources, since all their capacity might be allocated.
            Task scheduling with communication delays is a well-researched problem that is known to be strongly NP-hard problems for both homogeneous and heterogeneous resources \cite{orrOptimalTaskScheduling2021}.
            Numerous polynomial-time heuristic algorithms have been proposed that provide non-optimal solutions, yet do so within a reasonable time frame in order to be used for scheduling. Recent developments in machine learning and large datasets that trace the behaviour of hyper-scale data centres \cite{vanooteghemWhatHyperscaleData2023} while executing various task types lay a promising groundwork to use deep learning techniques to provide a resource utilisation estimator that is trained on said immense amount of data and then fine-tuned for the specific infrastructure it is part of. 
            Various machine learning approaches to improve resource utilisation prediction and scheduling emerged in recent years as are mentioned in section \ref{ch:state-of-the-art}. Yet, there is no consensus on the best machine learning approach and while task scheduling is challenging, deep learning algorithms made promising progress in providing more accurate predictors in many fields.
            The wastage occurring in utilizing resources on large-scale systems (or computing clusters) is further described in sections \ref{sec:public-cloud-provider-traces-in-available-data-related-work} and \ref{sec:data-analysis-evaluation}.
            This wastage is the basis for the evaluation of potential improvements upon the currently used prediction methods.
            
            The scope is the analysis of available literature on machine learning techniques used to predict hardware utilisation of tasks and how the authors did implement the state-of-the-art algorithms to improve the predictions.
            An overview of the theoretical concepts regarding the required terminology of scheduling and machine learning is done in order to provide the reader with knowledge of the subjects in this thesis.
            Also, an analysis of real data traces is done, that compares the actual hardware utilisation regarding the CPU and memory allocation and the deviation of the provided utilisation prediction corresponding to both hardware types. This analysis also shows the need to improve upon the currently used variant of prediction to better utilise the available hardware clusters. 
            An implementation of a Long-Short Term Memory neural network model and its related components and architecture are further elaborated upon. Different model configurations are analysed and compared regarding their prediction accuracy.


            % TODO Is there something missing from the motivation?
            % TODO add the scope
            % TODO elaborate the wastage

        %     This masters thesis is a product of the work done for the project \emph{DataCloud} and a published paper \emph{Big Data Pipeline Scheduling and Adaptation on the Computing Continuum} \cite{kimovskiBigDataPipeline2022}.

        %     \begin{quote}
        %         The Computing Continuum, covering Cloud, Fog, and Edge systems, promises to provide on-demand resource-as-a-service for Internet applications with diverse requirements, ranging from extremely low latency to high-performance processing. However, eminent challenges in automating the resources management of Big Data pipelines across the Computing Continuum remain. The resource management and adaptation for Big Data pipelines across the Computing Continuum require significant research effort, as the current data processing pipelines are dynamic. In contrast, traditional resource management strategies are static, leading to inefficient pipeline scheduling and overly complex process deployment. To address these needs, we propose in this work a scheduling and adaptation approach implemented as a software tool to lower the technological barriers to the management of Big Data pipelines over the Computing Continuum. The approach separates the static scheduling from the run-time execution, empowering domain experts with little infrastructure and software knowledge to take an active part in the Big Data pipeline adaptation. We conduct a feasibility study using a digital healthcare use case to validate our approach. We illustrate concrete scenarios supported by demonstrating how the scheduling and adaptation tool and its implementation automate the management of the lifecycle of a remote patient monitoring, treatment, and care pipeline \cite{kimovskiBigDataPipeline2022}.
        %     \end{quote}
        %     Our motivation is to improve the resource utilisation in distributed infrastructures consisting of a vast amount of computing resources, which in term also results in reduced costs for the providers as well as reduced energy consumption based on the number of tasks finished.
        %     The wastage occurring in utilizing resources on large-scale systems (or computing clusters) is further described in sections \ref{sec:public-cloud-provider-traces-in-available-data-related-work} and \ref{sec:data-analysis-evaluation}.
        %     The reduction of resource wastage is presented by our \nameref{sec:scheduling-and-adaptation-background} approach. 
        %     This approach consists of two main parts. One is the matching game-based scheduling algorithm, which is presented in the publication \emph{Matching-based Scheduling of Asynchronous Data Processing Workflows on the Computing Continuum} \cite{mehranMatchingbasedSchedulingAsynchronous2022} that decides which tasks are mapped to a resource via a two-sided ranking procedure, and second is the adaptation, that consists of continuous monitoring of the tasks and resources, as well as analysis of both and adapting them depending with the help of various tools.

        \section{Research Problems}
        \label{sec:research-problems-introduction}

            The deviation of the predicted provisioning or utilisation of heterogeneous resources done by humans often leads to the degradation of the entire system. That degradation includes deployed tasks not finishing within an expected time frame or even the failure of a resource, degrading the stability of the system further.
            \begin{quote}
                In practice, the planned or expected performance of production units often deviates from the actual performance. Most of these deviations are negative, which means that the actual performance is worse than the expected performance. Apparently, expectations about future performances are often too optimistic \cite{stoopComplexitySchedulingPractice1996}.
            \end{quote}
            Naive predictions of the resource utilisation generated by humans are likely to be over-utilising resources, which leads to resource wastage since those resources are not optimally operating. 
            
            These deviations from the actual values are also referred to as \emph{disturbances}.
            As is stated in \cite{stoopComplexitySchedulingPractice1996}, these disturbances can be divided into three categories:
            \begin{enumerate}
                \item Disturbances regarding the capacity,
                \item Disturbances related to orders,
                \item Disturbances related to the measurement of data.
            \end{enumerate}
            While the paper uses the disturbances on \emph{production scheduling}, i.e. finding a schedule for a real facility, the propositions can be translated into our domain of distributed systems that represent the machines/workers and big data pipelines filled with tasks that represent the tasks that are to be scheduled to the machines. After scheduling and deploying the tasks onto the machines, they need to be executed or finished by a worker.
            Capacity disturbances are caused by the machine's capacity and involve scenarios such as partial or complete failure of a hardware resource or trying to execute tasks on resources that are not capable of handling those tasks because the specific requirements are not met.
        
            Order-related disturbances are aspects that delay the process of individual orders (tasks).
            This could be the unavailability of required data that is calculated by a preceding task the current task depends on which has not finished its execution.

            The disturbance related to the measurement of data is that of processing times and hardware utilisation requirements that are estimated before deploying a task onto the distributed system. 
            This type of disturbance is the aforementioned deviation of the predicted utilisation of heterogeneous resources that are investigated in this thesis. These cover the hardware utilisation requirements and the already existing estimations done by domain experts and users. While analysing the monitoring traces of popular cloud providers, it becomes apparent that hardware is not optimally used.

        % explain that a subset of the problem is np-hard/complete

        
        \section{Research Objectives}
        \label{sec:research-objectives-introduction}

            The research objectives of this thesis work are to provide a prediction method for a distributed system handling big data that can predict how much system resources are necessary and provide a rule-based analyser that monitors the system components for over-utilisation.
            This is achieved by analysing existing real-data traces provided by cloud providers and using the gained knowledge to build fine-tuned predictors for the given task pipelines. One objective is to improve upon the existing prediction methods, such as predictions provided by users of cloud services, which have to provide an estimation of the resource utilisation the task that is to be deployed will require. 
            The prediction performance is measured using regression metrics in order to make informed decisions regarding prediction accuracy.

        \section{Research Goals}
        \label{sec:goals-results-introduction}

            \begin{itemize}
                \item An analysis of different publicly available monitoring traces.
                \item Reviewing different methods and theories for resource utilisation prediction.
                \item A proof of concept machine learning component that is capable of improving resource utilisation compared to other methods, which includes evaluation of the improvement.
                \item Providing the adapted data prediction done by the machine learning component in a reasonable time frame in order to be usable by the matching-based scheduler.
                
            \end{itemize}
            
        \section{Research Methodology}
        \label{sec:research-methodology-introduction}

            The research methodology is split into multiple segments.
            First, the state-of-the-art (see section \ref{ch:state-of-the-art}) approaches and algorithms were analysed based on their prediction performance, their applicability to the research problem and the feasibility of implementing each approach. This involves researching suitable scheduling and machine learning methods. Next, based on the available real-data cluster traces, an analysis is conducted to compare and decide on a well-fitted prediction variant.

            Further, an analysis of the real-data traces is done to use the available data effectively based on the chosen methods.
            This involves well-researched statistical analysis and transformations of the datasets. These steps are used to increase the likelihood of machine learning models learning the sequential patterns and inner attributes of the dataset.

            The different machine learning models are compared using various regression metrics that are commonly used to analyse the prediction performance of trained models. This is done to be consistent and comparable with other works in related fields and to ensure an easy process of reproducing the testbed and evaluations.

            

        % Research methodology is a systematic approach to planning, conducting, and analyzing research. It involves the use of various techniques, tools, and strategies to gather and analyze data in order to answer a research question or test a hypothesis.

        % The research methodology involves various steps, including identifying the research problem, formulating research questions, designing a study, selecting a sample, collecting data, analyzing data, and drawing conclusions. The methodology can vary depending on the research design, the field of study, and the research question being investigated.

        % Some common research methodologies include quantitative research, which involves the use of numerical data and statistical analysis, and qualitative research, which focuses on exploring subjective experiences and perceptions through interviews, observations, and other non-numerical data collection methods.

        % Overall, a well-designed research methodology is crucial for ensuring the validity and reliability of research findings and conclusions.
        

        
        \section{Thesis Outline}
        \label{sec:thesis-outline-introduction}

            First, in chapter \nameref{ch:background} the necessary background regarding monitoring, computation on large-scale distributed systems, a scheduling and adaptation approach and forecast prediction with machine learning is explained, followed by related work in machine learning-based forecast prediction and findings in publicly available data traces.
            In chapter \nameref{ch:model-methodology} the methodology of this thesis is explained. 
            In chapter \nameref{ch:architecture-and-implementation} the architecture of the software is explained, followed by the preprocessing of data traces mentioned in \nameref{sec:public-cloud-provider-traces-in-available-data-related-work} and the adaptation approach used.
            Next, in chapter \nameref{ch:evaluation-and-results} an analysis of the available data is done, followed by the metrics used for the evaluation, and finally, the different evaluation scenarios and their results are described.
            Finalizing the thesis with the chapter \nameref{ch:conclusions-and-future-work} that contains the conclusions about the findings of the evaluation in \nameref{sec:conclusions} as well as the \nameref{sec:future-work} that mentions possible improvements upon the current state of the software.


