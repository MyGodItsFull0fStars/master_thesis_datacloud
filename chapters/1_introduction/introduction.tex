\chapter{Introduction}
\label{ch:introduction}

    Modern large-scale systems that contain a vast amount of heterogeneous resources require complex workflow sequences in order to functionally operate. Additionally, specific domain knowledge is required to be able to properly map tasks residing on a big data pipeline onto heterogeneous resources. Yet, this often results in a degradation of the performance of the system since research shows that humans tend to over-provision the available resources.

    \begin{quote}
        In a data center, computing resources such as CPU and memory are usually managed by a resource manager. The resource manager accepts resource requests from users and allocates resources to their applications. A commonly known problem in resource management is that users often request more resources than their applications actually use. This leads to the degradation of overall resource utilization in a data center. \cite{thonglekImprovingResourceUtilization2019}
    \end{quote}

    This chapter covers the introduction of the master thesis.
    First, the motivation and scope of the thesis will be described in section \ref{sec:motivation-and-scope-introduction}.
    Followed by the explanation, of what the existing research problems are, that we want to improve upon in section \ref{sec:research-problems-introduction}. Next are the research objectives in section \ref{sec:research-objectives-introduction}, which describe briefly what the gained insights and improvements upon the research problems are. In section \ref{sec:research-methodology-introduction} the methodology of this thesis is described. And in section \ref{sec:thesis-outline-introduction} the outline of the thesis briefly describes the structure and content of all subsequent chapters.

        \section{Motivation and Scope}
        \label{sec:motivation-and-scope-introduction}

            This masters thesis is a product of the work done for the project \emph{DataCloud} and a produced paper \emph{Big Data Pipeline Scheduling and Adaptation on the Computing Continuum} \cite{kimovskiBigDataPipeline2022}.

            \begin{quote}
                The Computing Continuum, covering Cloud, Fog, and Edge systems, promises to provide on-demand resource-as-a-service for Internet applications with diverse requirements, ranging from extremely low latency to high-performance processing. However, eminent challenges in automating the resources management of Big Data pipelines across the Computing Continuum remain. The resource management and adaptation for Big Data pipelines across the Computing Continuum require significant research effort, as the current data processing pipelines are dynamic. In contrast, traditional resource management strategies are static, leading to inefficient pipeline scheduling and overly complex process deployment. To address these needs, we propose in this work a scheduling and adaptation approach implemented as a software tool to lower the technological barriers to the management of Big Data pipelines over the Computing Continuum. The approach separates the static scheduling from the run-time execution, empowering domain experts with little infrastructure and software knowledge to take an active part in the Big Data pipeline adaptation. We conduct a feasibility study using a digital healthcare use case to validate our approach. We illustrate concrete scenarios supported by demonstrating how the scheduling and adaptation tool and its implementation automate the management of the lifecycle of a remote patient monitoring, treatment, and care pipeline. \cite{kimovskiBigDataPipeline2022}
            \end{quote}
            Our motivation is to improve the resource utilisation in systems consisting of a vast amount of computing resources, which in term also results in reduced costs for the providers as well as reduced energy consumption based on the number of tasks finished.
            The wastage occurring in utilizing resources on large-scale systems (or computing clusters) is further described in sections \ref{sec:public-cloud-provider-traces-in-available-data-related-work} and \ref{sec:data-analysis-evaluation}.
            The reduction of resource wastage is presented by our \nameref{sec:scheduling-and-adaptation-background} approach. 
            This approach consists of two main parts. One is the matching game-based scheduling algorithm, which is presented in the publication \emph{Matching-based Scheduling of Asynchronous Data Processing Workflows on the Computing Continuum} \cite{mehranMatchingbasedSchedulingAsynchronous2022} that decides which tasks are mapped to a resource via a two-sided ranking procedure, and second is the adaptation, that consists of continuous monitoring of the tasks and resources, as well as analysis of both and adapting them depending with the help of various tools.

        % this is a test \cite{datacloudAbout}
        \section{Research Problems}
        \label{sec:research-problems-introduction}

        The deviation of the predicted provisioning or utilisation of heterogeneous resources done by humans often leads to the degradation of the entire system. That degradation includes deployed tasks not finishing within an expected time frame or even the failure of a resource, degrading the stability of the system further.
        \begin{quote}
            In practice, the planned or expected performance of production units often deviates from the actual performance. Most of these deviations are negative, which means that the actual performance is worse than the expected performance. Apparently, expectations about future performances are often too optimistic. \cite{stoopComplexitySchedulingPractice1996}
        \end{quote}
        Naive predictions of the resource utilisation generated by humans are likely to be over-utilizing resources, which leads to resource wastage since those resources are not optimally operating.
        % explain that a subset of the problem is np-hard/complete
        \section{Research Objectives}
        \label{sec:research-objectives-introduction}

            The research objectives of this thesis work are to provide a prediction method for a distributed system handling big data that can predict how much system resources are necessary and provide a rule-based analyser that monitors the system components for over-utilisation.

        \section{Research Methodology}
        \label{sec:research-methodology-introduction}

        
        \section{Goals/Expected Result}
        \label{sec:goals-results-introduction}

            \begin{itemize}
                \item An analysis of different publicly available monitoring traces.
                \item Reviewing different methods and theories for resource utilisation prediction.
                \item A proof of concept machine learning component that is capable of improving resource utilisation compared to other methods, which includes evaluation of the improvement.
                
            \end{itemize}
        
        \section{Thesis Outline}
        \label{sec:thesis-outline-introduction}

            First, in chapter \nameref{ch:background} the necessary background regarding monitoring, computation on large-scale distributed systems, a scheduling and adaptation approach and forecast prediction with machine learning is explained, followed by related work in machine learning-based forecast prediction and findings in publicly available data traces.
            In chapter \nameref{ch:model-methodology} the methodology of this thesis is explained. 
            In chapter \nameref{ch:architecture-and-implementation} the architecture of the software is explained, followed by the preprocessing of data traces mentioned in \nameref{sec:public-cloud-provider-traces-in-available-data-related-work} and the adaptation approach used.
            Next, in chapter \nameref{ch:evaluation-and-results} an analysis of the available data is done, and then the evaluation setup on how to set up the software is explained, followed by the different scenarios that were evaluated. 
            Finalizing the thesis with the chapter \nameref{ch:conclusions-and-future-work} that contains the conclusions about the findings of the evaluation in \nameref{sec:conclusions} as well as the \nameref{sec:future-work} that mentions possible improvements upon the current state of the software.


