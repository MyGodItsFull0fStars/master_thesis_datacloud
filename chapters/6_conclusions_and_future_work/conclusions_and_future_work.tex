

\chapter{Conclusions and Future Work}
\label{ch:conclusions-and-future-work}

    % TODO write short paragraph about chapter

    \section{Conclusions}
    \label{sec:conclusions}
    % I tried to solve the resource utilisation, introduced a new ML approach that I fully developed, and test on real data.

    % Discuss the results and describe why they are suitable for predicting resource utilisation.

        In this master's thesis, I provided an approach for solving resource utilisation in large-scale computing clusters.
        This was done by introducing a new machine learning approach based on Long-Short-Term Memory (LSTM) neural networks that I fully developed.
        The evaluation scenarios that were used to analyse the performance of the LSTM models were tested with real data provided by Alibaba.
        The source of this dataset are monitoring traces of a GPU cluster of approximately 1800 computing devices.
        The required utilisation for each task was estimated for both CPU and memory requirements.

        The acquired inference results were compared with a dataset that contained the actual resource utilisation of CPU and memory for each task and each LSTM model variant. Additionally, the LSTM results were also compared with the user-predicted values for each task which were provided to the Alibaba GPU cluster for the task to be deployed with the estimated allocation values.

        Regarding the evaluation scenarios, the Task LSTM (see \ref{sec:adding-task-knowledge-evaluation-scenarios}) did perform the best for predicting the CPU utilisation for the general use case. Yet, it could not predict CPU utilisation spikes, and the model variants Instance LSTM and Penalty LSTM did perform better when predicting those spikes. The Instance LSTM also had better prediction accuracy regarding memory utilisation compared to the Task LSTM. Both variants did perform better than the user predictions regarding the RMSE metric, yet performed worse for \emph{MAPE} and slightly worse for \emph{sMAPE}.
        
        The custom loss function \emph{Penalty Mean Squared Error (PMSE)} did perform better in predicting utilisation spikes, yet it also is likely to over-estimate the resource utilisation, which results in a worse performance than the user predictions for memory utilisation also had the better prediction performance for CPU utilisation regarding the metrics \emph{MAPE} and \emph{sMAPE} than the Instance LSTM variant.
        The improvements are promising and further evaluations regarding this loss function or a new variant (see section \ref{sec:improve-pmse-loss-function-future-work}) should be done in future work.

        For the \nameref{sec:rmse-metrics-evaluation} metric, the LSTM variants performed $2\%-27\%$ better than the user predictions for CPU utilisation, and for memory utilisation the LSTM variants Task and Instance LSTM performed $17\%-20\%$ better and the other variants slightly worse with $5\%$ than the user predictions.
        For the \nameref{sec:mape-metrics-evaluation}, the LSTM variants performed $19\%-53\%$ better for CPU utilisation but worse for the memory utilisation by $70\%-160\%$ compared to the user predictions.
        For the \nameref{sec:smape-metrics-evaluation}, the LSTM variants did perform $1.6-7.5\%$ better for CPU utilisation but slightly worse for memory utilisation by $12\%-31\%$ than the user predictions.
        Therefore, there is potential for improvement regarding memory utilisation.

        Overall, the LSTM models did perform worse when predicting memory utilisation the more information is fed as a feature set to them and the more complex they have become.
        Additionally, not one LSTM variant did outperform the other LSTM model variants in all regression metrics.
        Each had a specific strength, which will require additional research to generalise the training in a manner to result in an LSTM model that is suitable for most task types. 
        The prediction improvements for CPU utilisation did improve regarding every regression metric, yet the predictions for memory utilisation were still outperformed in many scenarios by the user predictions. 
        The improvements in CPU utilisation predictions indicate that similar improvements are possible for memory utilisation, even if they have yet not been achieved.



    \section{Future Work}
    \label{sec:future-work}

        This section contains possible future work on how the contents of this thesis would be extended in the future.
        These extensions cover topics such as energy consumption and \COTWO emissions, implementation details, comparisons with other datasets, comparisons with other machine learning architectures, improving the PMSE loss function and using additional machine learning components to improve the prediction performance of the LSTM variants covered in this thesis.
        
        In the current state of the implementation, the energy consumption is not taken into account.
        Energy consumption and the resulting \COTWO emissions of computing devices have become important topics in recent years.

        While the components of the Adaptation Loop described in section \ref{sec:adaptation-saa-background} work independently and to some degree can be used with one another, the full integration of the Adaptation Loop is yet not fully implemented nor tested.
        In the following sections, missing integration steps are explained, as to why they need to be implemented in order for the system to be functional.

        While the LSTM model that used the PMSE loss function did gain performance gains over other variants in some scenarios, it also was likely to overestimate the actual resource utilisation for both CPU and memory usage.
        A well-suited penalty value could improve prediction accuracy.

        The results of the LSTM variants are promising for the chosen GPU cluster traces. 
        Yet, these cluster traces only contain various machine-learning tasks. 
        Alibaba provides access to other monitoring traces, each with its specific focus, such as micro-services.
        Similarly, Google provides monitoring traces of their clusters, thus one possible evaluation scenario for future work is the comparison of a GPU cluster dataset by Google to see how well the LSTM variants perform on these cluster traces.

        While researching possible resource utilisation machine learning approaches, other model architectures were also considered.
        One very promising machine learning architecture is called \emph{Graph Neural Networks (GNN)}.
        GNNs are capable of doing inference on an arbitrary number of tasks (similar to LSTMs), yet one major advantage is their characteristic of not requiring the tasks to be ordered.

        One reason the Alibaba dataset of the GPU cluster was chosen is task independence, i.e. no task has dependencies on other tasks in the dataset.
        This characteristic of independence made the process of predicting resource utilisation simpler to implement.
        Since many tasks that are being executed on distributed infrastructures do have dependencies on other tasks and are often deployed onto different resources, it is necessary to take these dependencies into account when predicting the utilisation and deploying the tasks to resources.

        