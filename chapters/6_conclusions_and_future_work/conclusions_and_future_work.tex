

\chapter{Conclusions and Future Work}
\label{ch:conclusions-and-future-work}

    \section{Conclusions}
    \label{sec:conclusions}

    % I tried to solve the resource utilisation, introduced new ML approach that I fully developed, and test on real data.

    % Discussing the results, and describe why they are suitable for predicting resource utilistation.

    \section{Future Work}
    \label{sec:future-work}

    % How I would extend my work on the thesis.

        \subsection{Energy Consumption and \COTWO Emissions}
        \label{sec:energy-consumption-future-work}

            In the current state of the implementation, the energy consumption is not taken into account.
            Energy consumption and the resulting \COTWO emissions of computing devices have become important topics in recent years.

            \begin{quote}
                Carbon dioxide emissions are the primary driver of global climate change. It's widely recognised that to avoid the worst impacts of climate change, the world needs to urgently reduce emissions. But, how this responsibility is shared between regions, countries, and individuals has been an endless point of contention in international discussions \cite{ritchieCOGreenhouseGas2020}. 
            \end{quote}

            Possible evaluation scenarios are the energy consumption and \COTWO emissions that are produced while training the different LSTM model variants (see \ref{sec:evaluation-scenarios}) and analyse how much the model complexity and data dimensionality impact both. 
            This could be done either by using a static amount of training epochs for all LSTM models or train the models until they reach a predefined loss value. In the second variant, the model complexity and data dimensionality are likely to have a larger impact on energy consumption and \COTWO emissions.

            Another evaluation scenario is to generate a simulation that is similar to the real dataset of the Alibaba GPU cluster to monitor the energy consumption and \COTWO emissions for different prediction variants and compare the results.
            This comparison would be similar to the provided evaluations in the \nameref{sec:evaluation-scenarios}, but also provide metrics for the energy consumption and \COTWO emissions.

            % Energy Consumption of Machine Learning Algorithms while training, inference
            % Also consumption of task execution on GPU clusters, and if energy can be saved by using smarter predictors

        \subsection{Adaptation Loop}
        \label{sec:adaptation-loop-future-work}

            % Mention that the adaptation is not fully tested or included
            % Mention that the adaptation loop should be tested with some edge cases such as really bad schedule and how it is corrected

        \subsection{Comparison with other Datasets}
        \label{sec:comparison-with-other-datasets-future-work}

            % Mention the Google Cluster Dataset and also the other Alibaba datasets

        \subsection{Analyse and Integrate the Dependencies of Tasks}
        \label{sec:analyse-and-integrate-the-dependencies-of-tasks-future-work}

            % Explain that the current dataset does not have dependencies 
            % And that this is a future improvement to the current state

        \subsection{Explore other Machine Learning Algorithms}
        \label{sec:explore-other-machine-learning-algorithms-future-work}

            % Mention to include other ML algos to the LSTM to see if improvements are possible such as VAE after LSTM
            % Mention GNN as another approach

        \subsection{Improve PMSE Loss Function}
        \label{sec:improve-pmse-loss-function-future-work}

    % * Energy 
    % -- to see the influence of the energy consumption and possible improvement.
    % -- to investigate if energy was reduced or not
    % * Adaption Loop
    % * Compare with other datasets
    % * Analyze the dependencies of tasks
    % * Explore with other ML ALGOS such as GNN