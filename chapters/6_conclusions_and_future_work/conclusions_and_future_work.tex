

\chapter{Conclusions and Future Work}
\label{ch:conclusions-and-future-work}

    % TODO write short paragraph about chapter

    \section{Conclusions}
    \label{sec:conclusions}
    % I tried to solve the resource utilisation, introduced a new ML approach that I fully developed, and test on real data.

    % Discuss the results and describe why they are suitable for predicting resource utilisation.

        In this master's thesis, I provided an approach for solving resource utilisation in large-scale computing clusters.
        This was done by introducing a new machine learning approach based on Long-Short-Term Memory (LSTM) neural networks that I fully developed.
        The evaluation scenarios that were used to analyse the performance of the LSTM models were tested with real data provided by Alibaba.
        The source of this dataset are monitoring traces of a GPU cluster of approximately 1800 computing devices.
        The required utilisation for each task was estimated for both CPU and memory requirements.

        The acquired inference results were compared with a dataset that contained the actual resource utilisation of CPU and memory for each task and each LSTM model variant. Additionally, the LSTM results were also compared with the user-predicted values for each task which were provided to the Alibaba GPU cluster for the task to be deployed with the estimated allocation values.

        Regarding the evaluation scenarios, the Task LSTM (see \ref{sec:adding-task-knowledge-evaluation-scenarios}) did perform the best for predicting the CPU utilisation for the general use case. Yet, it could not predict CPU utilisation spikes, and the model variants Instance LSTM and Penalty LSTM did perform better when predicting those spikes. The Instance LSTM also had better prediction accuracy regarding memory utilisation compared to the Task LSTM. Both variants did perform better than the user predictions regarding the RMSE metric, yet performed worse for \emph{MAPE} and slightly worse for \emph{sMAPE}.
        
        The custom loss function \emph{Penalty Mean Squared Error (PMSE)} did perform better in predicting utilisation spikes, yet it also is likely to over-estimate the resource utilisation, which results in a worse performance than the user predictions for memory utilisation also had the better prediction performance for CPU utilisation regarding the metrics \emph{MAPE} and \emph{sMAPE} than the Instance LSTM variant.
        The improvements are promising and further evaluations regarding this loss function or a new variant (see section \ref{sec:improve-pmse-loss-function-future-work}) should be done in future work.

        Overall, the LSTM models did perform worse when predicting memory utilisation the more information is fed as a feature set to them and the more complex they have become.
        Additionally, not one LSTM variant did outperform the other LSTM model variants in all regression metrics.
        Each had a specific strength, which will require additional research to generalise the training in a manner to result in an LSTM model that is suitable for most task types. 



    \section{Future Work}
    \label{sec:future-work}

    % TODO
    % How I would extend my work on the thesis.

        \subsection{Energy Consumption and \COTWO Emissions}
        \label{sec:energy-consumption-future-work}

            In the current state of the implementation, the energy consumption is not taken into account.
            Energy consumption and the resulting \COTWO emissions of computing devices have become important topics in recent years.

            \begin{quote}
                Carbon dioxide emissions are the primary driver of global climate change. It's widely recognised that to avoid the worst impacts of climate change, the world needs to urgently reduce emissions. But, how this responsibility is shared between regions, countries, and individuals has been an endless point of contention in international discussions \cite{ritchieCOGreenhouseGas2020}. 
            \end{quote}

            Possible evaluation scenarios are the energy consumption and \COTWO emissions that are produced while training the different LSTM model variants (see \ref{sec:evaluation-scenarios}) and analyse how much the model complexity and data dimensionality impact both. 
            This could be done either by using a static amount of training epochs for all LSTM models or train the models until they reach a predefined loss value. In the second variant, the model complexity and data dimensionality are likely to have a larger impact on energy consumption and \COTWO emissions.

            Another evaluation scenario is to generate a simulation that is similar to the real dataset of the Alibaba GPU cluster to monitor the energy consumption and \COTWO emissions for different prediction variants and compare the results.
            This comparison would be similar to the provided evaluations in the \nameref{sec:evaluation-scenarios}, but also provide metrics for the energy consumption and \COTWO emissions.

        \subsection{Adaptation Loop}
        \label{sec:adaptation-loop-future-work}

            While the components of the Adaptation Loop described in section \ref{sec:adaptation-saa-background} work independently and to some degree can be used with one another, the full integration of the Adaptation Loop is yet not fully implemented nor tested.
            In the following sections, missing integration steps are explained, as to why they need to be implemented in order for the system to be functional.
            Similarly, the testing environment section contains suggestions for test scenarios that enable the analysis of the Adaptation Loop behaviour under stress and existing mismanagement of tasks and resources.

            \paragraph{Full Integration}
            Full integration into a live system is the next step that requires the following steps:
            \begin{itemize}
                \item Processing batches of recently monitored data to be used as training data for the LSTM model and continuously training the model on monitored data in order to gain higher accuracy and react to recent trends.
                \item Provide a process to easily deploy LSTM models for inference. A possible way to deploy LSTM models in a scalable manner are \emph{PyTorch TorchScripts} \cite{inkawhichSavingLoadingModels}.
                \item Provide a wrapper for incoming and outgoing data that is sent to and from the LSTM model to be easily used with other components such as monitoring tools and the \CMATCH scheduler.
            \end{itemize}

            \paragraph{Testing Environment}
            For testing the system, the following scenarios should be implemented to test the Adaptation Loop for its stability and its feasibility:
            \begin{itemize}
                \item Create a small testbed with a few Cloud, Fog and Edge devices. This should be done to be able to reach utilisation limits on the desired devices. Reaching the limits of a resource has the goal of analysing the behaviour of the Adaptation Loop in such a scenario.
                \item Provide a schedule plan that maps tasks to not suited resources on purpose. This should be done to see the behaviour of the Adaptation Loop when its rule-based system notifies it of the resources not being used in a reasonable manner.
                \item Provide a schedule plan that while being within utilisation and finishing time goals still has potential for improvement.
            \end{itemize}

        \subsection{Improve PMSE Loss Function}
        \label{sec:improve-pmse-loss-function-future-work}

            While the LSTM model that used the PMSE loss function did gain some performance gains over other variants in some scenarios, it also was likely to overestimate the actual resource utilisation for both CPU and memory usage.
            One option for improving the predictions might be to find a well-suited penalty value that is added to the loss function.
            In the evaluation scenario \ref{sec:training-with-custom-loss-function-evaluation-scenarios} the PMSE loss function used a penalty value of $0.05$ in case the predicted value was underestimating the utilisation. 
            This penalty value is likely too high given the trend of overestimating in the inference. Further tests are required to find a penalty value that compensates for the prediction of underestimated values while not overestimating by a too high distance to the actual value.
            Also, a static penalty value might not be the best option for adding a penalty to a loss function.

            Another option, that does not use a static penalty value might be to multiply a penalty value with the resulting loss of each loss element instead of adding a value. This would penalise predicted values that have a higher distance to the actual value than those that are close to the actual value.
            
            Additionally, it could be tested to penalise both the over- and underestimation regarding the distance to the actual values.
            This might result in the LSTM model not overestimating as much as the current version does.
        \subsection{Comparison with other Datasets}
        \label{sec:comparison-with-other-datasets-future-work}

            % Mention the Google Cluster Dataset and also the other Alibaba datasets

        \subsection{Analyse and Integrate the Dependencies of Tasks}
        \label{sec:analyse-and-integrate-the-dependencies-of-tasks-future-work}

            % Explain that the current dataset does not have dependencies 
            % And that this is a future improvement to the current state

        \subsection{Explore other Machine Learning Algorithms}
        \label{sec:explore-other-machine-learning-algorithms-future-work}

            % Mention to include other ML algos to the LSTM to see if improvements are possible such as VAE after LSTM
            % Mention GNN as another approach


    % * Energy 
    % -- to see the influence of the energy consumption and possible improvement.
    % -- to investigate if energy was reduced or not
    % * Adaption Loop
    % * Compare with other datasets
    % * Analyze the dependencies of tasks
    % * Explore with other ML ALGOS such as GNN