\section*{Abstract}
  \label{sec:abstract}
%   The research problems that this thesis aims to address are related to resource utilisation in hyperscale distributed infrastructures consisting of cloud, fog, and edge systems. Mapping and deploying tasks on these infrastructures is challenging, and providing accurate resource utilisation estimates is essential for enabling these infrastructures to function properly. A significant issue is the quality of the accuracy of the resource utilisation estimates, which tends to be overestimated by more than 30\% on average. This leads to a higher allocation of resources than necessary, resulting in instability and inefficiency of the infrastructure. Task scheduling with communication delays is also a well-known NP-hard problem, for both homogeneous and heterogeneous resources. To solve these problems, machine learning approaches have been proposed, but there is no consensus on the best approach, and deep learning algorithms have shown promise in providing more accurate predictors in many fields. The thesis aims to use Long-Short-Term Memory to provide a resource utilisation estimator trained on large datasets that trace the behaviour of hyperscale data centres while executing various task types, which can then be fine-tuned for the specific infrastructure it is part of. The objective is to provide accurate resource utilisation estimates to reduce over-provisioning, increase resource utilisation of under-utilised resources, stabilise the overall distributed infrastructure, and optimize task scheduling. 

%   The scope of the thesis is to address the aforementioned problems related to resource utilisation in distributed infrastructures. The focus is on machine learning techniques for providing accurate resource utilisation estimates, and the target infrastructure consists of cloud, fog, and edge systems. The thesis will not cover the implementation of a fully functional system but will instead focus on providing a proof-of-concept solution. The proposed solution will be evaluated on a simulated infrastructure, and the limitations and potential improvements will be discussed. Furthermore, the thesis will not address issues related to security and privacy in large-scale distributed infrastructures.

This thesis tackles resource utilisation issues in large-scale distributed infrastructures comprising cloud, fog, and edge systems. Accurate resource utilisation estimates are essential for proper infrastructure functioning. However, current estimates tend to be overestimated by over 30\%, resulting in the allocation of more resources than necessary and leading to instability and inefficiency. Additionally, scheduling tasks with communication delays is a well-known NP-hard problem, both for homogeneous and heterogeneous resources. Machine learning approaches have been proposed, but there is no consensus on the best approach. Deep learning algorithms have shown promise in providing accurate predictors. This thesis proposes using Long-Short-Term Memory to train a resource utilisation estimator on large datasets and fine-tune it for specific infrastructures to reduce over-provisioning, increase resource utilisation, stabilize the infrastructure, and optimise task scheduling. The thesis focuses on providing a proof-of-concept solution, evaluating it on a simulated infrastructure, and discussing potential improvements and limitations. 
% The thesis does not address security and privacy issues in large-scale distributed infrastructures.
  \vfill